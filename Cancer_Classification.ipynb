{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM81oZF/Q4J44CZqHnYoSe+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wwinski/cancer-classification-proj/blob/master/Cancer_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55kMJLYYju0w",
        "colab_type": "text"
      },
      "source": [
        "# The contents of this notebook are based on a project from my ML class. The main purpose of this project is to train a model to predict types of tumors, but it also highlights the importance of preprocessing your data. Below you will see the outcome of training models on raw data, even when attempting to optimize hyperparameters.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhX-QbZmGMmM",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries and data from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukStiAfm5Y_b",
        "colab_type": "code",
        "outputId": "489f9c58-b87f-4b0b-cb9b-0402912ec478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbdBf45a_q8E",
        "colab_type": "code",
        "outputId": "48c4d95b-e4de-433a-c2f8-01cccbcbe9a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "data = pd.read_csv(\"gdrive/My Drive/Datasets/Cancer Classification Data.csv\")\n",
        "labels = pd.read_csv(\"gdrive/My Drive/Datasets/Cancer Classification Labels.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEZN0mkOGcGB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Data can be found [here](https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq#)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F65awW3G9aNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prevents warning from prinitng\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "\n",
        "warnings.warn = warn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut8au0TdG7iL",
        "colab_type": "text"
      },
      "source": [
        "## View the training dataset to see what we're working with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDCVglYL7RLe",
        "colab_type": "code",
        "outputId": "5ca4e228-86dd-47b5-fd52-dcb2a57d64c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "data_df = data.rename(columns={'Unnamed: 0': 'Sample'}).set_index('Sample')\n",
        "data_labels = labels.rename(columns={'Unnamed: 0': 'Sample'}).set_index('Sample')\n",
        "data_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gene_0</th>\n",
              "      <th>gene_1</th>\n",
              "      <th>gene_2</th>\n",
              "      <th>gene_3</th>\n",
              "      <th>gene_4</th>\n",
              "      <th>gene_5</th>\n",
              "      <th>gene_6</th>\n",
              "      <th>gene_7</th>\n",
              "      <th>gene_8</th>\n",
              "      <th>gene_9</th>\n",
              "      <th>gene_10</th>\n",
              "      <th>gene_11</th>\n",
              "      <th>gene_12</th>\n",
              "      <th>gene_13</th>\n",
              "      <th>gene_14</th>\n",
              "      <th>gene_15</th>\n",
              "      <th>gene_16</th>\n",
              "      <th>gene_17</th>\n",
              "      <th>gene_18</th>\n",
              "      <th>gene_19</th>\n",
              "      <th>gene_20</th>\n",
              "      <th>gene_21</th>\n",
              "      <th>gene_22</th>\n",
              "      <th>gene_23</th>\n",
              "      <th>gene_24</th>\n",
              "      <th>gene_25</th>\n",
              "      <th>gene_26</th>\n",
              "      <th>gene_27</th>\n",
              "      <th>gene_28</th>\n",
              "      <th>gene_29</th>\n",
              "      <th>gene_30</th>\n",
              "      <th>gene_31</th>\n",
              "      <th>gene_32</th>\n",
              "      <th>gene_33</th>\n",
              "      <th>gene_34</th>\n",
              "      <th>gene_35</th>\n",
              "      <th>gene_36</th>\n",
              "      <th>gene_37</th>\n",
              "      <th>gene_38</th>\n",
              "      <th>gene_39</th>\n",
              "      <th>...</th>\n",
              "      <th>gene_20491</th>\n",
              "      <th>gene_20492</th>\n",
              "      <th>gene_20493</th>\n",
              "      <th>gene_20494</th>\n",
              "      <th>gene_20495</th>\n",
              "      <th>gene_20496</th>\n",
              "      <th>gene_20497</th>\n",
              "      <th>gene_20498</th>\n",
              "      <th>gene_20499</th>\n",
              "      <th>gene_20500</th>\n",
              "      <th>gene_20501</th>\n",
              "      <th>gene_20502</th>\n",
              "      <th>gene_20503</th>\n",
              "      <th>gene_20504</th>\n",
              "      <th>gene_20505</th>\n",
              "      <th>gene_20506</th>\n",
              "      <th>gene_20507</th>\n",
              "      <th>gene_20508</th>\n",
              "      <th>gene_20509</th>\n",
              "      <th>gene_20510</th>\n",
              "      <th>gene_20511</th>\n",
              "      <th>gene_20512</th>\n",
              "      <th>gene_20513</th>\n",
              "      <th>gene_20514</th>\n",
              "      <th>gene_20515</th>\n",
              "      <th>gene_20516</th>\n",
              "      <th>gene_20517</th>\n",
              "      <th>gene_20518</th>\n",
              "      <th>gene_20519</th>\n",
              "      <th>gene_20520</th>\n",
              "      <th>gene_20521</th>\n",
              "      <th>gene_20522</th>\n",
              "      <th>gene_20523</th>\n",
              "      <th>gene_20524</th>\n",
              "      <th>gene_20525</th>\n",
              "      <th>gene_20526</th>\n",
              "      <th>gene_20527</th>\n",
              "      <th>gene_20528</th>\n",
              "      <th>gene_20529</th>\n",
              "      <th>gene_20530</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sample</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sample_0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.017209</td>\n",
              "      <td>3.265527</td>\n",
              "      <td>5.478487</td>\n",
              "      <td>10.431999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.175175</td>\n",
              "      <td>0.591871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.591871</td>\n",
              "      <td>1.334282</td>\n",
              "      <td>2.015391</td>\n",
              "      <td>0.591871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.591871</td>\n",
              "      <td>5.619994</td>\n",
              "      <td>1.334282</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.796088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.598651</td>\n",
              "      <td>7.215116</td>\n",
              "      <td>10.839070</td>\n",
              "      <td>6.620204</td>\n",
              "      <td>9.513538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.063658</td>\n",
              "      <td>7.764805</td>\n",
              "      <td>4.747656</td>\n",
              "      <td>13.714396</td>\n",
              "      <td>10.034496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.833458</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.370304</td>\n",
              "      <td>10.362393</td>\n",
              "      <td>5.589928</td>\n",
              "      <td>8.141964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.736583</td>\n",
              "      <td>7.037152</td>\n",
              "      <td>7.123480</td>\n",
              "      <td>10.967399</td>\n",
              "      <td>5.902800</td>\n",
              "      <td>3.719370</td>\n",
              "      <td>7.203554</td>\n",
              "      <td>6.042557</td>\n",
              "      <td>2.602077</td>\n",
              "      <td>7.425526</td>\n",
              "      <td>7.846957</td>\n",
              "      <td>2.824951</td>\n",
              "      <td>6.239396</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.469593</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.535978</td>\n",
              "      <td>6.968701</td>\n",
              "      <td>7.128881</td>\n",
              "      <td>7.175175</td>\n",
              "      <td>9.249369</td>\n",
              "      <td>7.025970</td>\n",
              "      <td>8.045563</td>\n",
              "      <td>7.475709</td>\n",
              "      <td>7.205236</td>\n",
              "      <td>4.926711</td>\n",
              "      <td>8.210257</td>\n",
              "      <td>9.723516</td>\n",
              "      <td>7.220030</td>\n",
              "      <td>9.119813</td>\n",
              "      <td>12.003135</td>\n",
              "      <td>9.650743</td>\n",
              "      <td>8.921326</td>\n",
              "      <td>5.286759</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sample_1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.592732</td>\n",
              "      <td>1.588421</td>\n",
              "      <td>7.586157</td>\n",
              "      <td>9.623011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.816049</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.587845</td>\n",
              "      <td>2.466601</td>\n",
              "      <td>1.004394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.055208</td>\n",
              "      <td>3.562621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.070470</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.949812</td>\n",
              "      <td>8.522476</td>\n",
              "      <td>1.174790</td>\n",
              "      <td>4.926991</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.819832</td>\n",
              "      <td>1.327170</td>\n",
              "      <td>13.286240</td>\n",
              "      <td>6.663316</td>\n",
              "      <td>0.587845</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.533302</td>\n",
              "      <td>0.811142</td>\n",
              "      <td>...</td>\n",
              "      <td>8.882967</td>\n",
              "      <td>9.898199</td>\n",
              "      <td>7.069401</td>\n",
              "      <td>7.186134</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.134993</td>\n",
              "      <td>6.648930</td>\n",
              "      <td>6.715701</td>\n",
              "      <td>9.536238</td>\n",
              "      <td>1.004394</td>\n",
              "      <td>5.555482</td>\n",
              "      <td>8.029260</td>\n",
              "      <td>6.366219</td>\n",
              "      <td>0.811142</td>\n",
              "      <td>7.991732</td>\n",
              "      <td>7.161001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.708877</td>\n",
              "      <td>0.811142</td>\n",
              "      <td>8.451689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.242336</td>\n",
              "      <td>8.046284</td>\n",
              "      <td>6.047558</td>\n",
              "      <td>8.572901</td>\n",
              "      <td>7.549030</td>\n",
              "      <td>7.019935</td>\n",
              "      <td>9.458940</td>\n",
              "      <td>9.190867</td>\n",
              "      <td>10.639259</td>\n",
              "      <td>4.593372</td>\n",
              "      <td>7.323865</td>\n",
              "      <td>9.740931</td>\n",
              "      <td>6.256586</td>\n",
              "      <td>8.381612</td>\n",
              "      <td>12.674552</td>\n",
              "      <td>10.517059</td>\n",
              "      <td>9.397854</td>\n",
              "      <td>2.094168</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sample_2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.511759</td>\n",
              "      <td>4.327199</td>\n",
              "      <td>6.881787</td>\n",
              "      <td>9.870730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.972130</td>\n",
              "      <td>0.452595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.452595</td>\n",
              "      <td>1.981122</td>\n",
              "      <td>1.074163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.683023</td>\n",
              "      <td>8.210248</td>\n",
              "      <td>4.195285</td>\n",
              "      <td>3.660427</td>\n",
              "      <td>8.970920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.796598</td>\n",
              "      <td>6.096650</td>\n",
              "      <td>9.861616</td>\n",
              "      <td>7.680507</td>\n",
              "      <td>3.119439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.452595</td>\n",
              "      <td>7.899526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.731098</td>\n",
              "      <td>6.967883</td>\n",
              "      <td>0.452595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.646323</td>\n",
              "      <td>0.452595</td>\n",
              "      <td>...</td>\n",
              "      <td>10.355637</td>\n",
              "      <td>10.423274</td>\n",
              "      <td>5.170201</td>\n",
              "      <td>6.194260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.677147</td>\n",
              "      <td>6.271990</td>\n",
              "      <td>7.089816</td>\n",
              "      <td>9.675220</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.224017</td>\n",
              "      <td>8.020402</td>\n",
              "      <td>6.967883</td>\n",
              "      <td>5.014445</td>\n",
              "      <td>8.400038</td>\n",
              "      <td>7.527555</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.997902</td>\n",
              "      <td>0.796598</td>\n",
              "      <td>7.761132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.820460</td>\n",
              "      <td>8.048983</td>\n",
              "      <td>6.661493</td>\n",
              "      <td>7.716332</td>\n",
              "      <td>6.745802</td>\n",
              "      <td>7.524667</td>\n",
              "      <td>8.602350</td>\n",
              "      <td>9.036654</td>\n",
              "      <td>10.336027</td>\n",
              "      <td>5.125213</td>\n",
              "      <td>8.127123</td>\n",
              "      <td>10.908640</td>\n",
              "      <td>5.401607</td>\n",
              "      <td>9.911597</td>\n",
              "      <td>9.045255</td>\n",
              "      <td>9.788359</td>\n",
              "      <td>10.090470</td>\n",
              "      <td>1.683023</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sample_3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.663618</td>\n",
              "      <td>4.507649</td>\n",
              "      <td>6.659068</td>\n",
              "      <td>10.196184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.843375</td>\n",
              "      <td>0.434882</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.434882</td>\n",
              "      <td>2.874246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.267356</td>\n",
              "      <td>8.306317</td>\n",
              "      <td>3.573556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.524616</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.913761</td>\n",
              "      <td>9.511573</td>\n",
              "      <td>6.469165</td>\n",
              "      <td>7.029895</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.267356</td>\n",
              "      <td>6.800641</td>\n",
              "      <td>7.742714</td>\n",
              "      <td>12.659474</td>\n",
              "      <td>8.299890</td>\n",
              "      <td>0.768587</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.670731</td>\n",
              "      <td>0.434882</td>\n",
              "      <td>...</td>\n",
              "      <td>10.074382</td>\n",
              "      <td>9.918261</td>\n",
              "      <td>7.117924</td>\n",
              "      <td>7.196145</td>\n",
              "      <td>0.434882</td>\n",
              "      <td>3.609755</td>\n",
              "      <td>8.896696</td>\n",
              "      <td>7.577096</td>\n",
              "      <td>10.731446</td>\n",
              "      <td>5.075383</td>\n",
              "      <td>2.175652</td>\n",
              "      <td>7.675435</td>\n",
              "      <td>6.840816</td>\n",
              "      <td>6.233192</td>\n",
              "      <td>8.899886</td>\n",
              "      <td>8.319085</td>\n",
              "      <td>1.791814</td>\n",
              "      <td>5.661134</td>\n",
              "      <td>1.464093</td>\n",
              "      <td>8.625727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.420095</td>\n",
              "      <td>7.784746</td>\n",
              "      <td>7.613915</td>\n",
              "      <td>8.963286</td>\n",
              "      <td>7.744699</td>\n",
              "      <td>7.924997</td>\n",
              "      <td>8.981473</td>\n",
              "      <td>8.665592</td>\n",
              "      <td>9.194823</td>\n",
              "      <td>6.076566</td>\n",
              "      <td>8.792959</td>\n",
              "      <td>10.141520</td>\n",
              "      <td>8.942805</td>\n",
              "      <td>9.601208</td>\n",
              "      <td>11.392682</td>\n",
              "      <td>9.694814</td>\n",
              "      <td>9.684365</td>\n",
              "      <td>3.292001</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sample_4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.655741</td>\n",
              "      <td>2.821547</td>\n",
              "      <td>6.539454</td>\n",
              "      <td>9.738265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.566967</td>\n",
              "      <td>0.360982</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.275841</td>\n",
              "      <td>2.141204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.889707</td>\n",
              "      <td>10.149150</td>\n",
              "      <td>2.967630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.047238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.435949</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.942120</td>\n",
              "      <td>8.821535</td>\n",
              "      <td>5.861429</td>\n",
              "      <td>7.755709</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.649386</td>\n",
              "      <td>5.570241</td>\n",
              "      <td>2.612801</td>\n",
              "      <td>13.556734</td>\n",
              "      <td>8.004754</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.587569</td>\n",
              "      <td>0.649386</td>\n",
              "      <td>...</td>\n",
              "      <td>10.129154</td>\n",
              "      <td>10.062303</td>\n",
              "      <td>6.911620</td>\n",
              "      <td>7.855149</td>\n",
              "      <td>0.360982</td>\n",
              "      <td>3.655810</td>\n",
              "      <td>7.255520</td>\n",
              "      <td>7.292607</td>\n",
              "      <td>10.779793</td>\n",
              "      <td>3.954001</td>\n",
              "      <td>6.991148</td>\n",
              "      <td>8.153248</td>\n",
              "      <td>7.508444</td>\n",
              "      <td>4.586531</td>\n",
              "      <td>9.152227</td>\n",
              "      <td>8.227717</td>\n",
              "      <td>0.360982</td>\n",
              "      <td>6.227104</td>\n",
              "      <td>0.649386</td>\n",
              "      <td>8.151879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.558289</td>\n",
              "      <td>8.673708</td>\n",
              "      <td>6.505099</td>\n",
              "      <td>8.948989</td>\n",
              "      <td>7.010366</td>\n",
              "      <td>7.364056</td>\n",
              "      <td>8.950646</td>\n",
              "      <td>8.233366</td>\n",
              "      <td>9.298775</td>\n",
              "      <td>5.996032</td>\n",
              "      <td>8.891425</td>\n",
              "      <td>10.373790</td>\n",
              "      <td>7.181162</td>\n",
              "      <td>9.846910</td>\n",
              "      <td>11.922439</td>\n",
              "      <td>9.217749</td>\n",
              "      <td>9.461191</td>\n",
              "      <td>5.110372</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 20531 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          gene_0    gene_1    gene_2  ...  gene_20528  gene_20529  gene_20530\n",
              "Sample                                ...                                    \n",
              "sample_0     0.0  2.017209  3.265527  ...    8.921326    5.286759         0.0\n",
              "sample_1     0.0  0.592732  1.588421  ...    9.397854    2.094168         0.0\n",
              "sample_2     0.0  3.511759  4.327199  ...   10.090470    1.683023         0.0\n",
              "sample_3     0.0  3.663618  4.507649  ...    9.684365    3.292001         0.0\n",
              "sample_4     0.0  2.655741  2.821547  ...    9.461191    5.110372         0.0\n",
              "\n",
              "[5 rows x 20531 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeRGPURi7XlS",
        "colab_type": "code",
        "outputId": "b8b80546-a360-422c-fefa-283bf1a47ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(801, 20531)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTIArXRoMVhk",
        "colab_type": "text"
      },
      "source": [
        "## One-hot encoding the class labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2suyqG8IPNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_mappings = {\n",
        "    'PRAD': [0,0,0,0,1],\n",
        "    'LUAD': [0,0,0,1,0],\n",
        "    'BRCA': [0,0,1,0,0],\n",
        "    'KIRC': [0,1,0,0,0],\n",
        "    'COAD': [1,0,0,0,0],\n",
        "}\n",
        "\n",
        "data_labels['Class'] = [label_mappings[x] for x in data_labels.Class]\n",
        "one_hot_labels = np.vstack(data_labels.Class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc7xnBWIQU88",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Purposefully not normalizing/scaling data at this point**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew9RRZVbIPyQ",
        "colab_type": "text"
      },
      "source": [
        "## Seperating the data into Train, Validation, and Testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ERx7q2JIP_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " x_train, x_test, y_train, y_test = train_test_split(data_df, one_hot_labels, test_size=0.2, random_state=1)\n",
        " x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqaCWZrrIQVj",
        "colab_type": "code",
        "outputId": "35750529-3dbb-4991-94cc-47dfd4ca773c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('x_train: ' + str(len(x_train)))\n",
        "print('x_val: ' + str(len(x_val)))\n",
        "print('x_test: ' + str(len(x_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train: 512\n",
            "x_val: 128\n",
            "x_test: 161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJUoX-IsNfss",
        "colab_type": "text"
      },
      "source": [
        "## Creating a single layer NN with Keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSZHBOfdIOtf",
        "colab_type": "code",
        "outputId": "53327a7b-5212-4f8d-d657-cff4a320104f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_dim=x_train.shape[1]))\n",
        "network.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network.fit(x_train, y_train, epochs=5, batch_size=128)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "512/512 [==============================] - 1s 3ms/step - loss: 8.8337 - acc: 0.3652\n",
            "Epoch 2/5\n",
            "512/512 [==============================] - 0s 349us/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 3/5\n",
            "512/512 [==============================] - 0s 357us/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 4/5\n",
            "512/512 [==============================] - 0s 351us/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 5/5\n",
            "512/512 [==============================] - 0s 373us/step - loss: 9.6331 - acc: 0.4023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2cc993a390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3pOjArmWbA4",
        "colab_type": "text"
      },
      "source": [
        "## Let's create a function so it's easier to test NN in the future"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUNspz6WlQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network(train_dat, train_labels, act_func, num_layers, neuron_count, epochs, batch_size):\n",
        "  network = models.Sequential()\n",
        "  network.add(layers.Dense(neuron_count, activation=act_func, input_dim=train_dat.shape[1]))\n",
        "  for i in range(1, num_layers):\n",
        "    network.add(layers.Dense(neuron_count, activation=act_func))\n",
        "  network.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "  network.compile(optimizer='rmsprop',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  network.fit(train_dat, train_labels, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We06wihnV4WW",
        "colab_type": "text"
      },
      "source": [
        "## Testing more layers in the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIBI83vtg3bl",
        "colab_type": "code",
        "outputId": "c3c29435-d352-469d-f66e-30ead3f0f593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "create_network(x_train, y_train, 'relu', 10, 512, 5, 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "512/512 [==============================] - 2s 4ms/step - loss: 7.6016 - acc: 0.3984\n",
            "Epoch 2/5\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 3/5\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 4/5\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 5/5\n",
            "512/512 [==============================] - 1s 2ms/step - loss: 9.6331 - acc: 0.4023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ6DNQHwg-BD",
        "colab_type": "code",
        "outputId": "1298d642-4bf5-4324-f1ee-7f9b51d0b112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "create_network(x_train, y_train, 'relu', 100, 512, 5, 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "512/512 [==============================] - 8s 16ms/step - loss: 3.8154 - acc: 0.3340\n",
            "Epoch 2/5\n",
            "512/512 [==============================] - 3s 7ms/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 3/5\n",
            "512/512 [==============================] - 3s 7ms/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 4/5\n",
            "512/512 [==============================] - 3s 7ms/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 5/5\n",
            "512/512 [==============================] - 3s 7ms/step - loss: 9.6331 - acc: 0.4023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnbpSgaahLsa",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "Adding more layers doesn't seem to help once we reach a certain accuracy\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeLHiBuWVt5",
        "colab_type": "text"
      },
      "source": [
        "## Testing more neurons per layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qySMe80fhhY0",
        "colab_type": "code",
        "outputId": "36f97c6e-5eee-4ff2-c66b-20af9016ddc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "create_network(x_train, y_train, 'relu', 5, 2048, 5, 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 8.1633 - acc: 0.3555\n",
            "Epoch 2/5\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 3/5\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 4/5\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 9.6331 - acc: 0.4023\n",
            "Epoch 5/5\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 9.6331 - acc: 0.4023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA2AeUUuhjy5",
        "colab_type": "code",
        "outputId": "240507c8-44f8-4fc1-e899-791df9fbd3ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "create_network(x_train, y_train, 'relu', 5, 4096, 5, 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "512/512 [==============================] - 18s 36ms/step - loss: 10.4511 - acc: 0.1758\n",
            "Epoch 2/5\n",
            "512/512 [==============================] - 14s 28ms/step - loss: 13.2848 - acc: 0.1758\n",
            "Epoch 3/5\n",
            "512/512 [==============================] - 14s 28ms/step - loss: 13.2848 - acc: 0.1758\n",
            "Epoch 4/5\n",
            "512/512 [==============================] - 15s 29ms/step - loss: 13.2848 - acc: 0.1758\n",
            "Epoch 5/5\n",
            "512/512 [==============================] - 14s 28ms/step - loss: 13.2848 - acc: 0.1758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uZsFOb3iByO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Accuracy went down when the model got too complex\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8aBXWUbiLWD",
        "colab_type": "text"
      },
      "source": [
        "## Check the data to see why we're stuck at 40% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhwkLF_QiTPi",
        "colab_type": "code",
        "outputId": "11ab9ab0-9091-4743-d6d7-110265450439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "lab_df = pd.DataFrame(y_train)\n",
        "lab_df = lab_df.rename(columns = {0: 'COAD', 1: 'KIRC', 2: 'BRCA', 3: 'LUAD', 4: 'PRAD'})\n",
        "lab_df.sum(axis=0) / len(lab_df.index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "COAD    0.087891\n",
              "KIRC    0.181641\n",
              "BRCA    0.402344\n",
              "LUAD    0.175781\n",
              "PRAD    0.152344\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ipsdj2BntVh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The data has BRCA class the most (40%), so the model is always guessing that\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QM_jwBiEJH6",
        "colab_type": "text"
      },
      "source": [
        "## Checking the same on validation set - reveals 30% BRCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n4tiNpgECoX",
        "colab_type": "code",
        "outputId": "5d2c4f49-aff2-4a7f-db26-00117f68029a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "lab_df = pd.DataFrame(y_val)\n",
        "lab_df = lab_df.rename(columns = {0: 'COAD', 1: 'KIRC', 2: 'BRCA', 3: 'LUAD', 4: 'PRAD'})\n",
        "lab_df.sum(axis=0) / len(lab_df.index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "COAD    0.125000\n",
              "KIRC    0.218750\n",
              "BRCA    0.304688\n",
              "LUAD    0.148438\n",
              "PRAD    0.203125\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xQLJalDoMnC",
        "colab_type": "text"
      },
      "source": [
        "## New function to create/train a model, uses validation set for reporting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U4lvqNdjySE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Will return the confusion matrix and classification report for the given model\n",
        "def train_network(act_func, num_layers, neuron_count, epochs, batch_size, optim):\n",
        "  network = models.Sequential()\n",
        "  network.add(layers.Dense(neuron_count, activation=act_func, input_dim=x_train.shape[1]))\n",
        "  for i in range(1, num_layers):\n",
        "    network.add(layers.Dense(neuron_count, activation=act_func))\n",
        "  network.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "  network.compile(optimizer=optim,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  network.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "  preds = network.predict(x_val)\n",
        "  preds = np.argmax(preds, axis=1)\n",
        "  actuals = np.argmax(y_val, axis=1)\n",
        "  return network, confusion_matrix(actuals, preds), classification_report(actuals, preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRHNvkyEmd-2",
        "colab_type": "text"
      },
      "source": [
        "## Function to train model on parameter combinations and plot outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwDh-JPnSGsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_optimum(param_combs, opt_param_index, xlab):\n",
        "  acc_dict = {}\n",
        "  opt_list = []\n",
        "  for combo in param_combs:\n",
        "    netw, conf, rep = train_network(*combo)\n",
        "    accuracy = float(rep.split('\\n')[8].split()[1])\n",
        "    opt_list.append((combo, accuracy))\n",
        "    acc_dict[combo[opt_param_index]] = accuracy\n",
        "    print(str(combo) + ': ' + str(accuracy))\n",
        "  \n",
        "  # graph_results(acc_dict, xlab) #Plots not working for some cases, removing for now\n",
        "  return opt_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5rdG6xp8bPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def graph_results(acc_dict, xlab):\n",
        "  tups = sorted(acc_dict.items())\n",
        "  x, y = zip(*tups)\n",
        "  plt.bar(x, y, align='center', alpha=0.6)\n",
        "  plt.xlabel(xlab)\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnrj7qCQmmRP",
        "colab_type": "text"
      },
      "source": [
        "## Searching for optimal hyperparameters - testing different parameter combinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMzMnv2Pm0XH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_dict = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF9mHX-wj2GJ",
        "colab_type": "code",
        "outputId": "9316b008-8db3-4804-c457-63c20d7b473b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#OPTIMIZER\n",
        "act_func_arr = ['sigmoid']\n",
        "num_layer_arr = [5]\n",
        "neuron_count_arr = [1024]\n",
        "epoch_arr = [25]\n",
        "batch_size_arr = [128]\n",
        "optim_arr = ['rmsprop', 'sgd', 'adam']\n",
        "param_set = [act_func_arr, num_layer_arr, neuron_count_arr, epoch_arr, batch_size_arr, optim_arr]\n",
        "param_combs = itertools.product(*param_set)\n",
        "\n",
        "opt_dict['Optimizer'] = get_optimum(param_combs, 5, 'Optimizer')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('sigmoid', 5, 1024, 25, 128, 'rmsprop'): 0.22\n",
            "('sigmoid', 5, 1024, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 5, 1024, 25, 128, 'adam'): 0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE3hT3hMlCfs",
        "colab_type": "code",
        "outputId": "81371903-2845-429e-f3f0-df064d18dc8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#ACTIVATION FUNCTION\n",
        "act_func_arr = ['relu', 'sigmoid', 'tanh']\n",
        "num_layer_arr = [5]\n",
        "neuron_count_arr = [1024]\n",
        "epoch_arr = [25]\n",
        "batch_size_arr = [128]\n",
        "optim_arr = ['sgd']\n",
        "param_set = [act_func_arr, num_layer_arr, neuron_count_arr, epoch_arr, batch_size_arr, optim_arr]\n",
        "param_combs = itertools.product(*param_set)\n",
        "\n",
        "opt_dict['Activation Function'] = get_optimum(param_combs, 0, 'Activation Function')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('relu', 5, 1024, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 5, 1024, 25, 128, 'sgd'): 0.3\n",
            "('tanh', 5, 1024, 25, 128, 'sgd'): 0.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb_kzxLnvI3S",
        "colab_type": "code",
        "outputId": "e51ead41-1011-476b-dc65-42ed731ee86b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#HIDDEN LAYERS\n",
        "act_func_arr = ['sigmoid']\n",
        "num_layer_arr = [4, 6, 8, 10, 12]\n",
        "neuron_count_arr = [1024]\n",
        "epoch_arr = [25]\n",
        "batch_size_arr = [128]\n",
        "optim_arr = ['sgd']\n",
        "param_set = [act_func_arr, num_layer_arr, neuron_count_arr, epoch_arr, batch_size_arr, optim_arr]\n",
        "param_combs = itertools.product(*param_set)\n",
        "\n",
        "opt_dict['Hidden Layers'] = get_optimum(param_combs, 1, 'Hidden Layers')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('sigmoid', 4, 1024, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 6, 1024, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 8, 1024, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 10, 1024, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 12, 1024, 25, 128, 'sgd'): 0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp6TC1i-vcKw",
        "colab_type": "code",
        "outputId": "7af888bf-9547-4dc6-b455-1067ff8a5ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#NEURON COUNT\n",
        "act_func_arr = ['sigmoid']\n",
        "num_layer_arr = [5]\n",
        "neuron_count_arr = [512, 1024, 2048]\n",
        "epoch_arr = [25]\n",
        "batch_size_arr = [128]\n",
        "optim_arr = ['sgd']\n",
        "param_set = [act_func_arr, num_layer_arr, neuron_count_arr, epoch_arr, batch_size_arr, optim_arr]\n",
        "param_combs = itertools.product(*param_set)\n",
        "\n",
        "opt_dict['Neuron Count'] = get_optimum(param_combs, 2, 'Neuron Count')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('sigmoid', 5, 512, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 5, 1024, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 5, 2048, 25, 128, 'sgd'): 0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB8s_CeptvGC",
        "colab_type": "code",
        "outputId": "b5127dd3-e9cd-4553-db5a-5f1ce26a407b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#EPOCH COUNT\n",
        "act_func_arr = ['sigmoid']\n",
        "num_layer_arr = [5]\n",
        "neuron_count_arr = [1024]\n",
        "epoch_arr = [5, 10, 25, 50]\n",
        "batch_size_arr = [128]\n",
        "optim_arr = ['sgd']\n",
        "param_set = [act_func_arr, num_layer_arr, neuron_count_arr, epoch_arr, batch_size_arr, optim_arr]\n",
        "param_combs = itertools.product(*param_set)\n",
        "\n",
        "opt_dict['Epoch Count'] = get_optimum(param_combs, 3, 'Epoch Count')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('sigmoid', 5, 1024, 5, 128, 'sgd'): 0.3\n",
            "('sigmoid', 5, 1024, 10, 128, 'sgd'): 0.3\n",
            "('sigmoid', 5, 1024, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 5, 1024, 50, 128, 'sgd'): 0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1ILGCHtvjm",
        "colab_type": "code",
        "outputId": "16bba922-e9d8-4025-f49c-7c518e9c1695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#BATCH SIZE\n",
        "act_func_arr = ['sigmoid']\n",
        "num_layer_arr = [5]\n",
        "neuron_count_arr = [1024]\n",
        "epoch_arr = [25]\n",
        "batch_size_arr = [32, 64, 128, 256]\n",
        "optim_arr = ['sgd']\n",
        "param_set = [act_func_arr, num_layer_arr, neuron_count_arr, epoch_arr, batch_size_arr, optim_arr]\n",
        "param_combs = itertools.product(*param_set)\n",
        "\n",
        "opt_dict['Batch Size'] = get_optimum(param_combs, 4, 'Batch Size')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('sigmoid', 5, 1024, 25, 32, 'sgd'): 0.3\n",
            "('sigmoid', 5, 1024, 25, 64, 'sgd'): 0.3\n",
            "('sigmoid', 5, 1024, 25, 128, 'sgd'): 0.3\n",
            "('sigmoid', 5, 1024, 25, 256, 'sgd'): 0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD8R6B4-JgTj",
        "colab_type": "text"
      },
      "source": [
        "## Regardless of hyperparameters, unable to do any better than guessing BRCA\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Scaling and Normalizing the data\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s5CND0_rFP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_data = preprocessing.StandardScaler().fit_transform(data_df)\n",
        "norm_data = preprocessing.normalize(scaled_data, norm='l2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-dHux9r0aGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " x_train, x_test, y_train, y_test = train_test_split(norm_data, one_hot_labels, test_size=0.2, random_state=1)\n",
        " x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqcQr-ziewRu",
        "colab_type": "text"
      },
      "source": [
        "## Retrying a basic NN with modified data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Xygeqg0qNp",
        "colab_type": "code",
        "outputId": "867cccc1-5801-4577-e39e-1bcd7250e1af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model, conf_m, report = train_network('relu', 5, 512, 5, 128, 'rmsprop')\n",
        "print(conf_m)\n",
        "print('\\n')\n",
        "print(report)\n",
        "print('\\n')\n",
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  0  0  0  0]\n",
            " [ 0 28  0  0  0]\n",
            " [ 0  0 39  0  0]\n",
            " [ 0  0  0 19  0]\n",
            " [ 0  0  0  0 26]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       1.00      1.00      1.00        28\n",
            "           2       1.00      1.00      1.00        39\n",
            "           3       1.00      1.00      1.00        19\n",
            "           4       1.00      1.00      1.00        26\n",
            "\n",
            "    accuracy                           1.00       128\n",
            "   macro avg       1.00      1.00      1.00       128\n",
            "weighted avg       1.00      1.00      1.00       128\n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_140 (Dense)            (None, 512)               10512384  \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 11,565,573\n",
            "Trainable params: 11,565,573\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-9bZD9bfwRt",
        "colab_type": "text"
      },
      "source": [
        "## 100% accuracy on the validation set, time to run on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7WSuhpHdHdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9Rx7rjrdjJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_set = []\n",
        "truth_set = []\n",
        "for pred, truth in zip(test_predictions, y_test):\n",
        "  pred_set.append(np.argmax(pred))\n",
        "  truth_set.append(np.argmax(truth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCBFzceBeRBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "eb944cfe-fef3-4153-d525-0e694253016e"
      },
      "source": [
        "conf_m = confusion_matrix(truth_set, pred_set)\n",
        "report = classification_report(truth_set, pred_set)\n",
        "print(conf_m)\n",
        "print('\\n')\n",
        "print(report)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[17  0  0  0  0]\n",
            " [ 0 25  0  0  0]\n",
            " [ 0  0 55  0  0]\n",
            " [ 0  0  0 32  0]\n",
            " [ 0  0  0  0 32]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       1.00      1.00      1.00        25\n",
            "           2       1.00      1.00      1.00        55\n",
            "           3       1.00      1.00      1.00        32\n",
            "           4       1.00      1.00      1.00        32\n",
            "\n",
            "    accuracy                           1.00       161\n",
            "   macro avg       1.00      1.00      1.00       161\n",
            "weighted avg       1.00      1.00      1.00       161\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isj8t54FjUJu",
        "colab_type": "text"
      },
      "source": [
        "## Obtained 100% accuracy on the testing set without optimizing hyperparameters, once the data was sufficiently preprocessed."
      ]
    }
  ]
}